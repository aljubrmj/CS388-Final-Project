{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Model_Train_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49LQqe2el6M1"
      },
      "source": [
        "# 0. Check your runtime - connect to GPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCIW3XX0l98H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf39d0c-ea17-467b-8cda-c97f6a174f11"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  2 18:34:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Et-M-FhTXK"
      },
      "source": [
        "## Note: Google colab does not offer permanent storage.  You can mount your drive if you so desire\n",
        "# 1. Download your code from Github! Be sure to replace repo_name with your fork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUW_eaY4ge35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323c3b93-0614-45d5-8bc4-bd337b89ad8f"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "repo_name = \"aljubrmj/mj-nlp-fp.git\"\n",
        "# Example\n",
        "# repo_name = \"gregdurrett/nlp-qa-finalproj.git\"\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{2}'.format(user, password, repo_name)\n",
        "\n",
        "!{cmd_string}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: aljubrmj\n",
            "Password: ··········\n",
            "Cloning into 'mj-nlp-fp'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 53 (delta 11), reused 18 (delta 8), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MClUwlARhvsx"
      },
      "source": [
        "# 2. Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_wwMma5hvPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddb67bb-55ca-4808-fd35-621831743db1"
      },
      "source": [
        "!bash ./setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Illegal option -s\n",
            "Usage: /usr/bin/which [-a] args\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 26.3M  100 26.3M    0     0  7437k      0  0:00:03  0:00:03 --:--:-- 7435k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 53.8M  100 53.8M    0     0   9.9M      0  0:00:05  0:00:05 --:--:-- 11.1M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3392k  100 3392k    0     0  1526k      0  0:00:02  0:00:02 --:--:-- 1526k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3069k  100 3069k    0     0  1372k      0  0:00:02  0:00:02 --:--:-- 1372k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2603k  100 2603k    0     0   586k      0  0:00:04  0:00:04 --:--:--  586k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   371  100   371    0     0    442      0 --:--:-- --:--:-- --:--:--   442\n",
            "100 1075k  100 1075k    0     0   358k      0  0:00:03  0:00:03 --:--:--  563k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  822M  100  822M    0     0  5191k      0  0:02:42  0:02:42 --:--:-- 5484k\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n",
            "\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TYpACBTh6hy"
      },
      "source": [
        "# 3. Train and Eval your model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_lLvgwFixQ6"
      },
      "source": [
        "## Train your model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRhrd9YmiEwf"
      },
      "source": [
        " !python3 main.py \\\n",
        "    --use_gpu \\\n",
        "    --model \"baseline\" \\\n",
        "    --model_path \"squad_model.pt\" \\\n",
        "    --train_path \"datasets/squad_train.jsonl.gz\" \\\n",
        "    --dev_path \"datasets/squad_adversarial_addonesent.jsonl.gz\" \\\n",
        "    --output_path \"squad_predictions.txt\" \\\n",
        "    --hidden_dim 256 \\\n",
        "    --bidirectional \\\n",
        "    --do_train \\\n",
        "    --do_test \\\n",
        "    --epochs 10 \\\n",
        "    --batch_size 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tvL__ni_Ih"
      },
      "source": [
        "## Evaluate it now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVM5y5AjFTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363f83c6-144b-4020-d98d-faf7e2f588ea"
      },
      "source": [
        "!python3 evaluate.py \\\n",
        "    --dataset_path \"datasets/squad_adversarial_addonesent.jsonl.gz\" \\\n",
        "    --output_path \"squad_predictions.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'EM': 36.43, 'F1': 46.76}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-nFoFX6DnLn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}